{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zsaawdxEqBn2"
      },
      "source": [
        "# üëπ Fera Formid√°vel 4.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yt2NbbaiqXnZ"
      },
      "source": [
        "> Atividade realizada em dupla: Caio Ruas (24010) e Thalles Cansi (24006)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "syQ1qSSHqvCE"
      },
      "source": [
        "Um novo n√≠vel de monstro aparece nas florestas m√°gicas de LUMI. Esta √© a primeira apari√ß√£o de um monstro do tipo **Fera Formid√°vel**. Para derrotar esta fera, precisaremos utilizar nossos conhecimentos de Redes Neurais para resolver um problema de\n",
        "classifica√ß√£o. Vamos treinar uma rede neural com dados da planta √çris [1] que √© um conjunto de dados cl√°ssico em tarefas de classifica√ß√£o, possui 150 amostras com 4 atributos (comprimento e largura das s√©palas e p√©talas) e 3 classes correspondentes √†s esp√©cies de √≠ris."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKOgrGOGu19p"
      },
      "source": [
        "![Flores de √çris](Imagens/Flores√çris.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-3zXRVo1vLpG"
      },
      "source": [
        "<center>\n",
        "Legenda 1: Diferen√ßas entre flores de √çris [2].\n",
        "</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Estaremos utilizando o mesmo c√≥digo da aula, provido pelo professor, para construir e treinar a rede neural."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üî¢ Valor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Esta √© a classe Valor, que representa um valor num√©rico com suporte a diferencia√ß√£o autom√°tica. Ela possui m√©todos para opera√ß√µes matem√°ticas, como adi√ß√£o, subtra√ß√£o, multiplica√ß√£o e exponencia√ß√£o, al√©m de m√©todos para calcular a fun√ß√£o sigmoide e backpropagation. √â not√≥rio lembrar que realizasse os c√°lculos mesmo com ordem invertida, onde o objeto Valor pode ser o primeiro ou segundo operando."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "class Valor:\n",
        "    \"\"\"\n",
        "    Classe que representa um valor num√©rico com suporte a diferencia√ß√£o autom√°tica.\n",
        "    \n",
        "    Cada inst√¢ncia armazena:\n",
        "      - data: o valor num√©rico.\n",
        "      - progenitor: tupla com os valores dos quais este foi derivado.\n",
        "      - operador_mae: string representando a opera√ß√£o que gerou o valor.\n",
        "      - grad: gradiente (inicialmente zero) usado no backpropagation.\n",
        "    \"\"\"\n",
        "    def __init__(self, data, progenitor=(), operador_mae=\"\", rotulo=\"\"):\n",
        "        \"\"\"\n",
        "        Inicializa uma inst√¢ncia de Valor.\n",
        "        \n",
        "        Args:\n",
        "            data (float): o valor num√©rico.\n",
        "            progenitor (tuple): valores anteriores que contribu√≠ram para este.\n",
        "            operador_mae (str): opera√ß√£o que gerou o valor.\n",
        "            rotulo (str): r√≥tulo opcional para identifica√ß√£o.\n",
        "        \"\"\"\n",
        "        self.data = data\n",
        "        self.progenitor = progenitor\n",
        "        self.operador_mae = operador_mae\n",
        "        self.rotulo = rotulo\n",
        "        self.grad = 0\n",
        "\n",
        "    def __repr__(self):\n",
        "        \"\"\"Retorna uma representa√ß√£o string simplificada do objeto.\"\"\"\n",
        "        return f\"Valor(data={self.data})\"\n",
        "\n",
        "    def __add__(self, outro_valor):\n",
        "        \"\"\"\n",
        "        Sobrecarga do operador de adi√ß√£o.\n",
        "        \n",
        "        Realiza a opera√ß√£o: self + outro_valor.\n",
        "        \n",
        "        Args:\n",
        "            outro_valor (Valor ou n√∫mero): valor a ser somado.\n",
        "        \n",
        "        Returns:\n",
        "            Valor: novo objeto representando a soma.\n",
        "        \"\"\"\n",
        "        if not isinstance(outro_valor, Valor):\n",
        "            outro_valor = Valor(outro_valor)\n",
        "            \n",
        "        progenitor = (self, outro_valor)\n",
        "        data = self.data + outro_valor.data\n",
        "        operador_mae = \"+\"\n",
        "        resultado = Valor(data, progenitor, operador_mae)\n",
        "        \n",
        "        def propagar_adicao():\n",
        "            self.grad += resultado.grad\n",
        "            outro_valor.grad += resultado.grad\n",
        "            \n",
        "        resultado.propagar = propagar_adicao\n",
        "        \n",
        "        return resultado\n",
        "\n",
        "    def __mul__(self, outro_valor):\n",
        "        \"\"\"\n",
        "        Sobrecarga do operador de multiplica√ß√£o.\n",
        "        \n",
        "        Realiza a opera√ß√£o: self * outro_valor.\n",
        "        \n",
        "        Args:\n",
        "            outro_valor (Valor ou n√∫mero): valor a ser multiplicado.\n",
        "        \n",
        "        Returns:\n",
        "            Valor: novo objeto representando o produto.\n",
        "        \"\"\"\n",
        "        if not isinstance(outro_valor, Valor):\n",
        "            outro_valor = Valor(outro_valor)\n",
        "            \n",
        "        progenitor = (self, outro_valor)\n",
        "        data = self.data * outro_valor.data\n",
        "        operador_mae = \"*\"\n",
        "        resultado = Valor(data, progenitor, operador_mae)\n",
        "        \n",
        "        def propagar_multiplicacao():\n",
        "            self.grad += resultado.grad * outro_valor.data\n",
        "            outro_valor.grad += resultado.grad * self.data\n",
        "            \n",
        "        resultado.propagar = propagar_multiplicacao\n",
        "        \n",
        "        return resultado\n",
        "\n",
        "    def exp(self):\n",
        "        \"\"\"\n",
        "        Calcula a exponencial do valor.\n",
        "        \n",
        "        Realiza a opera√ß√£o: exp(self).\n",
        "        \n",
        "        Returns:\n",
        "            Valor: novo objeto representando a exponencial.\n",
        "        \"\"\"\n",
        "        progenitor = (self, )\n",
        "        data = math.exp(self.data)\n",
        "        operador_mae = \"exp\"\n",
        "        resultado = Valor(data, progenitor, operador_mae)\n",
        "        \n",
        "        def propagar_exp():\n",
        "            self.grad += resultado.grad * data \n",
        "        \n",
        "        resultado.propagar = propagar_exp\n",
        "        \n",
        "        return resultado\n",
        "\n",
        "    def __pow__(self, expoente):\n",
        "        \"\"\"\n",
        "        Sobrecarga do operador de exponencia√ß√£o.\n",
        "        \n",
        "        Realiza a opera√ß√£o: self ** expoente.\n",
        "        \n",
        "        Args:\n",
        "            expoente (int ou float): expoente da opera√ß√£o.\n",
        "        \n",
        "        Returns:\n",
        "            Valor: novo objeto representando a exponencia√ß√£o.\n",
        "        \"\"\"\n",
        "        assert isinstance(expoente, (int, float)), \"Expoente deve ser um n√∫mero.\"\n",
        "        progenitor = (self, )\n",
        "        data = self.data ** expoente\n",
        "        operador_mae = f\"**{expoente}\"\n",
        "        resultado = Valor(data, progenitor, operador_mae)\n",
        "        \n",
        "        def propagar_pow():\n",
        "            self.grad += resultado.grad * (expoente * self.data ** (expoente - 1))\n",
        "        \n",
        "        resultado.propagar = propagar_pow\n",
        "        \n",
        "        return resultado\n",
        "\n",
        "    def __truediv__(self, outro_valor):\n",
        "        \"\"\"\n",
        "        Sobrecarga do operador de divis√£o.\n",
        "        \n",
        "        Realiza a opera√ß√£o: self / outro_valor.\n",
        "        \n",
        "        Args:\n",
        "            outro_valor (Valor ou n√∫mero): divisor.\n",
        "        \n",
        "        Returns:\n",
        "            Valor: novo objeto representando a divis√£o.\n",
        "        \"\"\"\n",
        "        return self * outro_valor ** (-1)\n",
        "\n",
        "    def __neg__(self):\n",
        "        \"\"\"\n",
        "        Sobrecarga do operador de nega√ß√£o.\n",
        "        \n",
        "        Realiza a opera√ß√£o: -self.\n",
        "        \n",
        "        Returns:\n",
        "            Valor: novo objeto representando o valor negativo.\n",
        "        \"\"\"\n",
        "        return self * -1\n",
        "\n",
        "    def __sub__(self, outro_valor):\n",
        "        \"\"\"\n",
        "        Sobrecarga do operador de subtra√ß√£o.\n",
        "        \n",
        "        Realiza a opera√ß√£o: self - outro_valor.\n",
        "        \n",
        "        Args:\n",
        "            outro_valor (Valor ou n√∫mero): valor a ser subtra√≠do.\n",
        "        \n",
        "        Returns:\n",
        "            Valor: novo objeto representando a subtra√ß√£o.\n",
        "        \"\"\"\n",
        "        return self + (-outro_valor)\n",
        "\n",
        "    def __radd__(self, outro_valor):\n",
        "        \"\"\"\n",
        "        Sobrecarga do operador de adi√ß√£o reversa.\n",
        "        \n",
        "        Permite opera√ß√µes onde Valor est√° √† direita: outro_valor + self.\n",
        "        \n",
        "        Args:\n",
        "            outro_valor (Valor ou n√∫mero): valor a ser somado.\n",
        "        \n",
        "        Returns:\n",
        "            Valor: resultado da adi√ß√£o.\n",
        "        \"\"\"\n",
        "        return self + outro_valor\n",
        "\n",
        "    def __rmul__(self, outro_valor):\n",
        "        \"\"\"\n",
        "        Sobrecarga do operador de multiplica√ß√£o reversa.\n",
        "        \n",
        "        Permite opera√ß√µes onde Valor est√° √† direita: outro_valor * self.\n",
        "        \n",
        "        Args:\n",
        "            outro_valor (Valor ou n√∫mero): valor a ser multiplicado.\n",
        "        \n",
        "        Returns:\n",
        "            Valor: resultado da multiplica√ß√£o.\n",
        "        \"\"\"\n",
        "        return self * outro_valor\n",
        "\n",
        "    def sig(self):\n",
        "        \"\"\"\n",
        "        Calcula a fun√ß√£o sigmoide.\n",
        "        \n",
        "        Realiza a opera√ß√£o: exp(self) / (exp(self) + 1).\n",
        "        \n",
        "        Returns:\n",
        "            Valor: novo objeto representando o resultado da sigmoide.\n",
        "        \"\"\"\n",
        "        return self.exp() / (self.exp() + 1)\n",
        "\n",
        "    def propagar(self):\n",
        "        \"\"\"\n",
        "        Fun√ß√£o de propaga√ß√£o (backpropagation) do gradiente.\n",
        "        \n",
        "        Este m√©todo deve ser sobrescrito pelas opera√ß√µes espec√≠ficas.\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "    def propagar_tudo(self):\n",
        "        \"\"\"\n",
        "        Executa o backpropagation atrav√©s de todos os n√≥s (valores) conectados.\n",
        "        \n",
        "        Atribui gradiente 1 ao v√©rtice folha e propaga recursivamente utilizando uma ordem topol√≥gica dos n√≥s.\n",
        "        \"\"\"\n",
        "        self.grad = 1\n",
        "        ordem_topologica = []\n",
        "        visitados = set()\n",
        "\n",
        "        def constroi_ordem_topologica(v):\n",
        "            if v not in visitados:\n",
        "                visitados.add(v)\n",
        "                for progenitor in v.progenitor:\n",
        "                    constroi_ordem_topologica(progenitor)\n",
        "                ordem_topologica.append(v)\n",
        "\n",
        "        constroi_ordem_topologica(self)\n",
        "\n",
        "        for vertice in reversed(ordem_topologica):\n",
        "            vertice.propagar()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDnVJkyOl0gc"
      },
      "source": [
        "Para termos o dataset e poder realizar as avalia√ß√µes da nossa rede neural, bem como realizar alguns c√°lculos matem√°ticos, vamos importar as bibliotecas necess√°rias e carregar o dataset. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "eA8pDI0gu1h-"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "O dataset Iris cont√©m informa√ß√µes sobre tr√™s esp√©cies de flores: setosa, versicolor e virginica. Cada amostra possui quatro atributos: comprimento e largura das s√©palas e p√©talas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal_length</th>\n",
              "      <th>sepal_width</th>\n",
              "      <th>petal_length</th>\n",
              "      <th>petal_width</th>\n",
              "      <th>species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sepal_length  sepal_width  petal_length  petal_width species\n",
              "0           5.1          3.5           1.4          0.2  setosa\n",
              "1           4.9          3.0           1.4          0.2  setosa\n",
              "2           4.7          3.2           1.3          0.2  setosa\n",
              "3           4.6          3.1           1.5          0.2  setosa\n",
              "4           5.0          3.6           1.4          0.2  setosa"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "iris = sns.load_dataset('iris')\n",
        "iris.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Vamos transformar as classes em valores num√©ricos e dividir os dados em conjuntos de treino e teste."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "le = LabelEncoder()\n",
        "iris['species'] = le.fit_transform(iris['species'])\n",
        "\n",
        "X = iris.drop('species', axis=1).values\n",
        "y = iris['species'].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Vamos usar a implementa√ß√£o de MLP j√° existente no notebook para criar e treinar a rede neural."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'MLP' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[13], line 7\u001b[0m\n\u001b[0;32m      3\u001b[0m CAMADAS_OCULTAS \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m5\u001b[39m]\n\u001b[0;32m      5\u001b[0m arquitetura_da_rede \u001b[38;5;241m=\u001b[39m CAMADAS_OCULTAS \u001b[38;5;241m+\u001b[39m [NUM_DADOS_DE_SAIDA]\n\u001b[1;32m----> 7\u001b[0m minha_mlp \u001b[38;5;241m=\u001b[39m \u001b[43mMLP\u001b[49m(NUM_DADOS_DE_ENTRADA, arquitetura_da_rede)\n",
            "\u001b[1;31mNameError\u001b[0m: name 'MLP' is not defined"
          ]
        }
      ],
      "source": [
        "NUM_DADOS_DE_ENTRADA = 4\n",
        "NUM_DADOS_DE_SAIDA = 3\n",
        "CAMADAS_OCULTAS = [5, 5]\n",
        "\n",
        "arquitetura_da_rede = CAMADAS_OCULTAS + [NUM_DADOS_DE_SAIDA]\n",
        "\n",
        "minha_mlp = MLP(NUM_DADOS_DE_ENTRADA, arquitetura_da_rede)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Vamos treinar a rede neural usando o conjunto de treino e calcular a perda em cada √©poca."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "NUM_EPOCAS = 200\n",
        "TAXA_DE_APRENDIZADO = 0.01\n",
        "\n",
        "for epoca in range(NUM_EPOCAS):\n",
        "    y_pred = []\n",
        "    for exemplo in X_train:\n",
        "        previsao = minha_mlp(exemplo)\n",
        "        y_pred.append(previsao)\n",
        "\n",
        "    erros = []\n",
        "    for yt, yp in zip(y_train, y_pred):\n",
        "        residuo = yp - yt\n",
        "        erro_quadratico = residuo**2\n",
        "        erros.append(erro_quadratico)\n",
        "    loss = sum(erros)\n",
        "\n",
        "    for p in minha_mlp.parametros():\n",
        "        p.grad = 0\n",
        "\n",
        "    loss.propagar_tudo()\n",
        "\n",
        "    for p in minha_mlp.parametros():\n",
        "        p.data = p.data - p.grad * TAXA_DE_APRENDIZADO\n",
        "\n",
        "    if epoca % 10 == 0:\n",
        "        print(f\"√âpoca {epoca}, Perda: {loss.data}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Avalia√ß√£o da Rede Neural\n",
        "\n",
        "Vamos avaliar o desempenho da rede neural no conjunto de teste."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ü§ì Neur√¥nio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A classe Neur√¥nio representa um neur√¥nio em uma rede neural. Ela possui pesos e um vi√©s, que s√£o inicializados aleatoriamente. O neur√¥nio calcula a sa√≠da usando a fun√ß√£o sigmoide e realiza o backpropagation para atualizar os pesos e o vi√©s com base no erro da previs√£o."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "\n",
        "class Neuronio:\n",
        "    \"\"\"\n",
        "    Representa um neur√¥nio simples com pesos e vi√©s para uso em uma rede neural.\n",
        "\n",
        "    Este neur√¥nio utiliza a classe Valor para armazenar seus par√¢metros e realizar a\n",
        "    diferencia√ß√£o autom√°tica durante o treinamento.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, num_dados_entrada):\n",
        "        \"\"\"\n",
        "        Inicializa um neur√¥nio com um n√∫mero especificado de entradas.\n",
        "\n",
        "        Args:\n",
        "            num_dados_entrada (int): n√∫mero de entradas para o neur√¥nio.\n",
        "        \"\"\"\n",
        "        self.vies = Valor(random.uniform(-1, 1))\n",
        "\n",
        "        self.pesos = []\n",
        "        for i in range(num_dados_entrada):\n",
        "            self.pesos.append(Valor(random.uniform(-1, 1)))\n",
        "\n",
        "    def __call__(self, x):\n",
        "        \"\"\"\n",
        "        Realiza a passagem forward do neur√¥nio.\n",
        "\n",
        "        Calcula a soma ponderada das entradas e aplica a fun√ß√£o sigmoide para\n",
        "        determinar a sa√≠da do neur√¥nio.\n",
        "\n",
        "        Args:\n",
        "            x (list[Valor]): lista de objetos Valor representando as entradas.\n",
        "\n",
        "        Returns:\n",
        "            Valor: objeto Valor representando a sa√≠da do neur√¥nio.\n",
        "        \"\"\"\n",
        "        assert len(x) == len(\n",
        "            self.pesos\n",
        "        ), \"O n√∫mero de entradas deve ser igual ao n√∫mero de pesos.\"\n",
        "\n",
        "        soma = 0\n",
        "        for info_entrada, peso_interno in zip(x, self.pesos):\n",
        "            soma += info_entrada * peso_interno\n",
        "\n",
        "        soma += self.vies\n",
        "\n",
        "        dado_de_saida = soma.sig()\n",
        "\n",
        "        return dado_de_saida\n",
        "\n",
        "    def parametros(self):\n",
        "        \"\"\"\n",
        "        Retorna uma lista com os par√¢metros do neur√¥nio (pesos e vi√©s).\n",
        "\n",
        "        Returns:\n",
        "            list[Valor]: lista contendo os pesos e o vi√©s.\n",
        "        \"\"\"\n",
        "        return self.pesos + [self.vies]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéÇ Camada"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A classe Camada representa uma camada de neur√¥nios em uma rede neural. Ela possui um n√∫mero espec√≠fico de neur√¥nios e √© respons√°vel por calcular a sa√≠da da camada com base nas entradas recebidas. Realiza o forward pass e agrega os parametros de cada neur√¥nio."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Camada:\n",
        "    \"\"\"\n",
        "    Representa uma camada em uma rede neural composta por m√∫ltiplos neur√¥nios.\n",
        "\n",
        "    Cada camada gerencia um conjunto de neur√¥nios, realizando a passagem forward\n",
        "    e agregando os par√¢metros (pesos e vi√©s) de cada neur√¥nio.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, num_neuronios, num_dados_entrada):\n",
        "        \"\"\"\n",
        "        Inicializa a camada com um n√∫mero espec√≠fico de neur√¥nios, cada um com\n",
        "        um determinado n√∫mero de entradas.\n",
        "\n",
        "        Args:\n",
        "            num_neuronios (int): n√∫mero de neur√¥nios na camada.\n",
        "            num_dados_entrada (int): n√∫mero de entradas para cada neur√¥nio.\n",
        "        \"\"\"\n",
        "        self.neuronios = []\n",
        "        for _ in range(num_neuronios):\n",
        "            neuronio = Neuronio(num_dados_entrada)\n",
        "            self.neuronios.append(neuronio)\n",
        "\n",
        "    def __call__(self, x):\n",
        "        \"\"\"\n",
        "        Realiza a passagem forward na camada.\n",
        "\n",
        "        Aplica cada neur√¥nio da camada √† mesma entrada e retorna os dados de sa√≠da.\n",
        "\n",
        "        Args:\n",
        "            x (list[Valor]): lista de objetos Valor representando as entradas da camada.\n",
        "\n",
        "        Returns:\n",
        "            Valor ou list[Valor]: sa√≠da de um √∫nico neur√¥nio se houver apenas um,\n",
        "            ou lista com as sa√≠das de todos os neur√¥nios.\n",
        "        \"\"\"\n",
        "        dados_de_saida = []\n",
        "        for neuronio in self.neuronios:\n",
        "            informacao = neuronio(x)\n",
        "            dados_de_saida.append(informacao)\n",
        "\n",
        "        if len(dados_de_saida) == 1:\n",
        "            return dados_de_saida[0]\n",
        "        else:\n",
        "            return dados_de_saida\n",
        "\n",
        "    def parametros(self):\n",
        "        \"\"\"\n",
        "        Agrega e retorna todos os par√¢metros (pesos e vi√©s) de cada neur√¥nio da camada.\n",
        "\n",
        "        Returns:\n",
        "            list[Valor]: lista contendo todos os par√¢metros dos neur√¥nios da camada.\n",
        "        \"\"\"\n",
        "        params = []\n",
        "        for neuronio in self.neuronios:\n",
        "            params_neuronio = neuronio.parametros()\n",
        "            params.extend(params_neuronio)\n",
        "\n",
        "        return params"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üß† MLP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Por fim, nossa √∫ltima classe da nossa rede neural √© a `MLP` (Multi-Layer Perceptron). Ela representa uma rede neural com m√∫ltiplas camadas. A `MLP` organiza as camadas da rede, permitindo a passagem forward dos dados e a agrega√ß√£o dos par√¢metros de todas as camadas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class MLP:\n",
        "    \"\"\"\n",
        "    Representa uma rede neural do tipo MLP (Multi-Layer Perceptron).\n",
        "\n",
        "    Essa classe organiza as camadas da rede, permitindo a passagem forward dos dados e\n",
        "    a agrega√ß√£o dos par√¢metros (pesos e vi√©s) de todas as camadas.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, num_dados_entrada, num_neuronios_por_camada):\n",
        "        \"\"\"\n",
        "        Inicializa a MLP com um n√∫mero definido de entradas e uma lista que especifica\n",
        "        o n√∫mero de neur√¥nios em cada camada.\n",
        "\n",
        "        Args:\n",
        "            num_dados_entrada (int): n√∫mero de entradas da rede.\n",
        "            num_neuronios_por_camada (list[int]): lista com o n√∫mero de neur√¥nios para cada camada.\n",
        "        \"\"\"\n",
        "        percurso = [num_dados_entrada] + num_neuronios_por_camada\n",
        "\n",
        "        camadas = []\n",
        "        for i in range(len(num_neuronios_por_camada)):\n",
        "            camada = Camada(num_neuronios_por_camada[i], percurso[i])\n",
        "            camadas.append(camada)\n",
        "\n",
        "        self.camadas = camadas\n",
        "\n",
        "    def __call__(self, x):\n",
        "        \"\"\"\n",
        "        Realiza a passagem forward pela rede.\n",
        "\n",
        "        Cada camada processa a entrada e o resultado √© passado para a pr√≥xima camada.\n",
        "\n",
        "        Args:\n",
        "            x (list[Valor] ou Valor): dados de entrada para a rede.\n",
        "\n",
        "        Returns:\n",
        "            Valor ou list[Valor]: sa√≠da final da rede ap√≥s a passagem por todas as camadas.\n",
        "        \"\"\"\n",
        "        for camada in self.camadas:\n",
        "            x = camada(x)\n",
        "        return x\n",
        "\n",
        "    def parametros(self):\n",
        "        \"\"\"\n",
        "        Agrega e retorna todos os par√¢metros (pesos e vi√©s) de todas as camadas da rede.\n",
        "\n",
        "        Returns:\n",
        "            list[Valor]: lista contendo os par√¢metros de cada camada.\n",
        "        \"\"\"\n",
        "        params = []\n",
        "        for camada in self.camadas:\n",
        "            parametros_camada = camada.parametros()\n",
        "            params.extend(parametros_camada)\n",
        "\n",
        "        return params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Avalia√ß√£o\n",
        "y_pred_test = []\n",
        "for exemplo in X_test:\n",
        "    previsao = minha_mlp(exemplo)\n",
        "    y_pred_test.append(np.argmax(previsao))\n",
        "\n",
        "# Calculando acur√°cia\n",
        "acuracia = np.mean(y_pred_test == y_test)\n",
        "print(f'Acur√°cia no conjunto de teste: {acuracia * 100:.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nEUC2Bj1tYre"
      },
      "source": [
        "# üìñ Refer√™ncias"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zRZ3m9tbtwO9"
      },
      "source": [
        "[1] Conjunto de dados Iris. UCI Machine Learning Repository. Dispon√≠vel em: https://archive.ics.uci.edu/dataset/53/iris. Acesso em: 05 de Abril de 2025.\n",
        "\n",
        "[2] Conjunto de dados Iris. Wikipedia. Dispon√≠vel em: https://pt.wikipedia.org/wiki/Conjunto_de_dados_flor_Iris. Acesso em: 05 de Abril de 2025."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
